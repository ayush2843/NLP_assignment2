{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCD0OfMlu2I1",
        "colab_type": "code",
        "outputId": "4c4928a3-ae82-4553-f690-d2893a2f5274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk \n",
        "from nltk import ngrams\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout,SimpleRNN \n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "import keras.utils as utils\n",
        "import re\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import math\n",
        "import codecs\n",
        "import random\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import operator\n",
        "import string\n",
        "from random import randrange as rd"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veFjdcpwyriu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file=open(\"speech_data.txt\",\"r\",encoding=\"UTF-8\")\n",
        "data=file.read()\n",
        "file.close()\n",
        "data = re.sub('SPEECH \\d+', '\\n', data)\n",
        "data = re.sub('â€™', \"'\",data)\n",
        "data = data.replace('...',' ')\n",
        "data = data.replace('..',' ')\n",
        "data = re.sub(\"[^A-Za-z.']\",' ',data)\n",
        "data = data.replace('\\n',' ')\n",
        "data = data.replace('  ',' ')\n",
        "data = data.replace('  ',' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A90r10yazEVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = sent_tokenize(data) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySIkUmsiBodr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad(tokens):\n",
        "  temp=[]\n",
        "  comp=[]\n",
        "  for i in tokens:\n",
        "    var=nltk.word_tokenize(i)\n",
        "    var.append(\"</s>\")\n",
        "    var.insert(0,\"<s>\")\n",
        "    temp.append(var)\n",
        "    for j in var:\n",
        "      comp.append(j)\n",
        "  return(temp,comp)\n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISXWSIv1cToz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def padding(lis):\n",
        "  sent_list=[]\n",
        "  token_list=[]\n",
        "  for i in lis:\n",
        "    i+=\"</s> \" \n",
        "    i=i[::-1]\n",
        "    i+=\" >s<\"\n",
        "    i=i[::-1]\n",
        "    sent_list.append(i)\n",
        "    token_list.append(i.split(\" \"))\n",
        "  return(sent_list,token_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaBXopHE_25v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent_list, comp = pad(tokens)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qAxolwm_4fB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_1, test_1 = train_test_split(sent_list, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN6mumD2DQkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_dict = {}\n",
        "vocab_len = 0\n",
        "for i in (train_1):\n",
        "  for j in i:\n",
        "    if(j in vocab_dict):\n",
        "      vocab_dict[j] += 1\n",
        "    else:\n",
        "      vocab_dict[j] = 1\n",
        "      vocab_len += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN5-c3jXeVjz",
        "colab_type": "text"
      },
      "source": [
        "# Get n gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sEEJRLweT2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ngram(lis,n):\n",
        "  poss={}\n",
        "  for i in lis:\n",
        "    for j in list(nltk.ngrams(i,n)):\n",
        "      if(j in poss):\n",
        "        poss[j]+=1\n",
        "      else:\n",
        "        poss[j]=1\n",
        "  return(poss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR858qgvImxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjuZ50jde4hQ",
        "colab_type": "text"
      },
      "source": [
        "# Unigram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4nytqXVe6iC",
        "colab_type": "code",
        "outputId": "3bcf91cc-61af-4358-8b67-d216220e9800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n=1\n",
        "uni=ngram(train_2,n)\n",
        "print(\"Number of Unigrams:\", len(list(uni.keys())))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Unigrams: 8877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht3eK0WCfWkR",
        "colab_type": "text"
      },
      "source": [
        "# BiGram "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkMwY8YdfY9B",
        "colab_type": "code",
        "outputId": "d7792505-4a90-4e51-8bd8-2a417a7f8f48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n=2\n",
        "bi=ngram(train_2,n)\n",
        "print(\"Number of Bigrams:\", len(list(bi.keys())))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Bigrams: 51157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty5negtCffzS",
        "colab_type": "text"
      },
      "source": [
        "# Trigram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVIanQn1fi6Y",
        "colab_type": "code",
        "outputId": "b8ba11b4-6384-4bf2-8dad-61ac80fa46f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n=3\n",
        "tri=ngram(train_2,n)\n",
        "print(\"Number of Trigrams:\", len(list(tri.keys())))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Trigrams: 90345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7AiBqxffpIG",
        "colab_type": "text"
      },
      "source": [
        "# Quadgrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu7u3co9fsh-",
        "colab_type": "code",
        "outputId": "3a0707dc-fae6-436e-fd32-260ed36b42a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n=4\n",
        "quad=ngram(train_2,n)\n",
        "print(\"Number of quadgrams:\", len(list(quad.keys())))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of quadgrams: 103023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcFsN0AcBw9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2GfMT4o-MZ5",
        "colab_type": "text"
      },
      "source": [
        "# MLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWDriMbY9nX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unig(word):\n",
        "  if(tuple(word) in uni):\n",
        "    return((uni[tuple(word)]+1)/(len(list(uni.keys()))+vocab_len))\n",
        "  else:\n",
        "    return 1/vocab_len\n",
        "def big(word):\n",
        "  if(tuple(word) in bi):\n",
        "    return ((bi[tuple(word)]+1))/(len(list(bi.keys()))+vocab_len)\n",
        "    \n",
        "  else:\n",
        "      return 1/vocab_len\n",
        "    \n",
        "def trig(word):\n",
        "  if(tuple(word) in tri):\n",
        "    return (tri[tuple(word)]+1)/(len(list(tri.keys()))+vocab_len)\n",
        "  else:\n",
        "      return 1/vocab_len\n",
        "            \n",
        "def quadg(word):\n",
        "  if(tuple(word) in quad):\n",
        "    return (quad[tuple(word)]+1)/(len(list(quad.keys()))+vocab_len)\n",
        "  else:\n",
        "      return 1/vocab_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0Ix_tqTBvsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "updated_test=[]\n",
        "for i in test_2:\n",
        "  for j in i:\n",
        "    updated_test.append(j)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TprwGorz_WNH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "20d74bd4-4efa-4a32-e147-c783798a3ff1"
      },
      "source": [
        "import random \n",
        "# unigram_=random.sample(updated_test,1)\n",
        "unigram_test=random.sample(updated_test,1)\n",
        "\n",
        "\n",
        "# Bigram_=random.sample(updated_test,1)\n",
        "Bigram_test=random.sample(updated_test,2)\n",
        "\n",
        "# trigram_=random.sample(updated_test,1)\n",
        "trigram_test=random.sample(updated_test,3)\n",
        "\n",
        "# quadgram_=random.sample(updated_test,1)\n",
        "quadgram_test=random.sample(updated_test,4)\n",
        "\n",
        "print(unig(unigram_test))\n",
        "print(big(Bigram_test))\n",
        "print(trig(trigram_test))\n",
        "print(quadg(quadgram_test))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.00014814814814814815\n",
            "0.00014814814814814815\n",
            "0.00014814814814814815\n",
            "0.00014814814814814815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9-2oeS8DDxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_string=\"\"\n",
        "for i in test_1:\n",
        "  \n",
        "  test_string+=i\n",
        "  test_string+=\" \""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLdVTMfQyHOX",
        "colab_type": "text"
      },
      "source": [
        "# perplexity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-6Kmn18_RuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Perprex(data,n):\n",
        "  if(n==1):\n",
        "    typp=unig\n",
        "  elif(n==2):\n",
        "    typp=big\n",
        "  elif(n==3):\n",
        "    typp=trig\n",
        "  elif(n==4):\n",
        "    typp=quadg\n",
        "  prob=0\n",
        "  tot_len=0\n",
        "  for i in data:\n",
        "    temp=0\n",
        "    for j in range(len(i)-n+1):\n",
        "      w = i[j:j+n]\n",
        "      \n",
        "      temp += math.log(typp(w),2)\n",
        "\n",
        "    temp=math.pow(2,temp)\n",
        "\n",
        "    prob -= math.log(temp,2)\n",
        "    sentence = i.split(\" \")\n",
        "    tot_len += (len(sentence)-n-1)\n",
        "  \n",
        "  return math.pow(2, prob/tot_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh2VNSyDKbz1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "024f5c1d-2669-41a8-f83b-2a4e0d72a010"
      },
      "source": [
        "print(\"unigram perplexity: \",Perprex(test_string, 1))\n",
        "print(\"bigram perplexity: \",Perprex(test_string, 2))\n",
        "print(\"trigram perplexity: \",Perprex(test_string, 3))\n",
        "print(\"quadgram perplexity: \",Perprex(test_string, 4))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "570.1665432242371\n",
            "51.86543504814822\n",
            "9.093378064057491\n",
            "2.081737140439814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N031H7Y14y5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaY7nw3ByS11",
        "colab_type": "text"
      },
      "source": [
        "# Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoj1pct4w0eJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Classical generator to generate new words using a n_gram model\n",
        "def MLE(n_gram, initial_sequence):\n",
        "  sentence = [\"<s>\"]\n",
        "  if(n_gram==1):\n",
        "    for i in range(20):\n",
        "      max_prob = 0\n",
        "      max_prob_list = list()\n",
        "      for j in vocab_dict.keys():\n",
        "        k = (unig([j]))\n",
        "        if(k>max_prob):\n",
        "          max_prob = k\n",
        "          max_prob_list = [j]\n",
        "        elif(k==max_prob):\n",
        "          max_prob_list.append(j)\n",
        "      samples = np.random.multinomial(20,[max_prob]*len(max_prob_list),size=1)\n",
        "      index, value = max(enumerate(samples), key = operator.itemgetter(1))\n",
        "      sentence.append(max_prob_list[index])\n",
        "  else:\n",
        "    sentence.extend(initial_sequence)\n",
        "    i = len(initial_sequence)\n",
        "    temp=0\n",
        "    while(sentence[-1]!=\"</s>\" and i<20):\n",
        "      max_prob = 0\n",
        "      max_prob_list = list()\n",
        "      for j in vocab_dict:\n",
        "        word_list = sentence[-n_gram+1:]\n",
        "        word_list.append(j)\n",
        "        if(n_gram==2):\n",
        "          k = big(word_list)\n",
        "        elif(n_gram==3):\n",
        "          k = trig(word_list)\n",
        "        elif(n_gram==4):\n",
        "          k = quadg(word_list)\n",
        "        if(k>max_prob):\n",
        "          max_prob = k\n",
        "          max_prob_list = [j]\n",
        "        elif(k==max_prob):\n",
        "          max_prob_list.append(j)\n",
        "      samples = np.random.multinomial(20,[max_prob]*len(max_prob_list),size=1)\n",
        "      max_len=len(max_prob_list)\n",
        "      index, value = max(enumerate(samples), key = operator.itemgetter(1))\n",
        "      sentence.append(max_prob_list[rd(0,max_len,1)])\n",
        "      i+=1\n",
        "  \n",
        "  return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYwnUqWyofNj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6bfa5cb7-520b-4651-9162-07b5e1a4c185"
      },
      "source": [
        "# GENERATING RANDOM TEXT:\n",
        "# UNIGRAMS\n",
        "print(\"UNIGRAM: \", end = \" \")\n",
        "print(\" \".join(MLE(1,[])))\n",
        "# BIGRAM\n",
        "print(\"BIGRAM: \", end = \" \")\n",
        "print(\" \".join(MLE(2,[\"it\", \"is\"])))\n",
        "# TRIGRAM\n",
        "print(\"TRIGRAM: \", end = \" \")\n",
        "print(\" \".join(MLE(3,[\"there\", \"is\", \"something\"])))\n",
        "# QUADGRAM\n",
        "print(\"QUADGRAM1: \", end = \" \")\n",
        "print(\" \".join(MLE(4,[\"but\", \"there\", \"is\", \"no\"])))\n",
        "# ANOTHER QuADGRAM\n"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UNIGRAM:  <s> the the the the the the the the the the the the the the the the the the the the\n",
            "BIGRAM:  <s> it is a lot of the way I think of the way I think of the way I think of\n",
            "TRIGRAM:  <s> there is something plans someone viciously decisions fricking still Robin Sir wars debates Defense lawyer ACHIEVEMENT LAW HIGH auctioned hitting\n",
            "QUADGRAM1:  <s> but there is no thrilled hand prefer damage Highly complicated CALLED richest REPRESENT Todd Half stated Street comfortable INDIRECTLY impression\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gieF5qc0fDeU",
        "colab_type": "text"
      },
      "source": [
        "The generated text is human readable, but isn't grammatically perfect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B12v5VTpCEy",
        "colab_type": "text"
      },
      "source": [
        "# Neural Approach "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzQ5eOXzW6YO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muh77smCW6eg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeF1mz9yW6jT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM5jwUY7W6ns",
        "colab_type": "code",
        "outputId": "877334c0-d1ae-4f3b-c064-21eb8cd3e033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv2S7ucgW6mZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}